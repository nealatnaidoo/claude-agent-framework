---
description: Generate a project-specific visiting agent prompt for external reviewers
allowed-tools: Bash(ls:*), Bash(find:*), Bash(grep:*), Bash(cat:*), Bash(sort:*), Bash(tail:*)
---

<visit>

## Context Discovery

Project manifest:
!`cat .claude/manifest.yaml 2>/dev/null || echo "NO_MANIFEST"`

Project structure:
!`ls -d src/ components/ lib/ app/ pages/ features/ entities/ shared/ widgets/ 2>/dev/null || echo "No standard source directories"`

Existing remediation:
!`cat .claude/remediation/remediation_tasks.md 2>/dev/null || echo "NO_REMEDIATION_FILE"`

Highest BUG ID:
!`grep -roh "BUG-[0-9]*" .claude/remediation/ 2>/dev/null | sort -t- -k2 -n | tail -1 || echo "BUG-000"`

Highest IMPROVE ID:
!`grep -roh "IMPROVE-[0-9]*" .claude/remediation/ 2>/dev/null | sort -t- -k2 -n | tail -1 || echo "IMPROVE-000"`

Tech stack indicators:
!`ls pyproject.toml package.json Cargo.toml go.mod pom.xml 2>/dev/null || echo "No standard config files"`

Evidence state:
!`ls .claude/evidence/ 2>/dev/null || echo "NO_EVIDENCE_DIR"`

Git info:
!`git log --oneline -5 2>/dev/null || echo "Not a git repository"`

## Your Task

You are generating a **visiting agent prompt** tailored to this specific project. The prompt will be given to an external reviewer (visiting agent) so they can review the project with full context.

### Step 1: Ask Review Type

Use AskUserQuestion to ask:

```
Question: "What type of visiting agent review do you need?"
Header: "Review type"
Options:
1. Security Audit (Recommended) - OWASP top 10, auth flows, secrets, injection points
2. Performance Analysis - Query optimization, response times, memory, bundle size
3. Accessibility Audit - WCAG compliance, keyboard nav, screen readers, contrast
4. Custom Review - Specify your own review focus area
```

### Step 2: Detect Project Context

From the context discovery above, determine:

1. **Tech stack**: Python/FastAPI, React/TypeScript, Rust, Go, etc.
2. **Architecture**: Hexagonal (components/), FSD (src/features/), monolith, microservices
3. **Current phase**: From manifest.yaml `phase` field
4. **Source directories**: Where code lives
5. **Test directories**: Where tests live
6. **Existing findings**: Current BUG/IMPROVE counts and highest IDs
7. **Evidence state**: Whether quality gates have been run

### Step 3: Generate the Visiting Agent Prompt

Based on the review type and project context, generate a complete visiting agent prompt.

Write the prompt to: `.claude/visiting_prompt_{role}_{date}.md`

The prompt MUST include these sections:

```markdown
# Visiting Agent Brief: {Role} Review

**Project**: {project name from manifest or directory}
**Date**: {today}
**Review Type**: {security_auditor|performance_analyst|accessibility_auditor|custom}
**Generated By**: /visit command

---

## Your Identity

You are a **visiting {role}** agent. You can READ and ANALYZE everything, but you CANNOT modify source code, mark tasks, or change workflow state.

**Reference**: `~/.claude/agents/visit.md` (full protocol)

---

## Project Context

**Tech Stack**: {detected stack}
**Architecture**: {detected architecture}
**Phase**: {current manifest phase}
**Last Review**: {from manifest.reviews if exists}

### Source Code Locations

{List actual directories that exist, e.g.:}
- `components/` - Backend hexagonal components
- `src/features/` - Frontend feature slices
- `src/shared/` - Shared UI kit and utilities

### Test Locations

{List actual test directories, e.g.:}
- `components/*/tests/` - Backend unit/integration tests
- `src/**/*.test.tsx` - Frontend component tests
- `tests/e2e/` - End-to-end Playwright tests

### Configuration Files

{List actual config files found}

---

## Entry Protocol

1. Read manifest: `.claude/manifest.yaml`
2. Read existing remediation: `.claude/remediation/remediation_tasks.md`
3. Note highest IDs: BUG-{NNN} and IMPROVE-{NNN}
4. Your new findings start at: BUG-{NNN+1} and IMPROVE-{NNN+1}

---

## Review Scope ({role}-specific)

{Generate role-specific checklist based on the actual project structure.}

{For security_auditor:}
### Files to Prioritize
- {actual auth/login files if found}
- {actual API handler files if found}
- {actual config/env handling files if found}

### Checks to Run
- `bandit -r {source_dir}` (Python security linter)
- `grep -r "password\|secret\|token\|api_key" {source_dir} --include="*.py"`
- {other stack-appropriate security tools}

{For performance_analyst:}
### Files to Prioritize
- {actual database/query files if found}
- {actual API endpoint files if found}
- {actual heavy computation files if found}

### Checks to Run
- Check for N+1 query patterns
- Check bundle size: `npm run build -- --stats` or equivalent
- {other stack-appropriate performance tools}

{For accessibility_auditor:}
### Files to Prioritize
- {actual UI component files if found}
- {actual form files if found}
- {actual navigation files if found}

### Checks to Run
- `npx axe-core {url}` or `npx @axe-core/cli`
- Check all interactive elements have data-testid and ARIA
- {other stack-appropriate accessibility tools}

---

## Output Requirements

### 1. Dated Review Report

Write to: `.claude/remediation/{role}_review_{date}.md`

Use this format for each finding:

#### BUG-{NNN}: {Title}
**Priority**: critical|high|medium|low
**Category**: {role}
**File**: {path/to/file.py:line}

**Evidence**: {What you observed}
**Expected**: {What should happen}
**Recommendation**: {How to fix - DO NOT implement}

#### IMPROVE-{NNN}: {Title}
**Priority**: should|could|won't
**Type**: {refactor|pattern|performance|readability|testability}
**File**: {path/to/file.py}

**Current**: {Current state}
**Proposed**: {Proposed improvement}
**Rationale**: {Why this matters}

### 2. Update Remediation Tracker

Append findings to: `.claude/remediation/remediation_tasks.md`

### 3. Update Manifest

Add your review to `.claude/manifest.yaml` under `reviews.external`.

---

## Governance Compliance (ALWAYS CHECK)

Regardless of your specialty, also verify:

| Requirement | How to Check |
|-------------|--------------|
| Hexagonal architecture | No framework imports in `{domain_dir}` |
| Determinism | No `datetime.now()`/`uuid4()`/`random.*` in core |
| Testing exists | `.claude/evidence/test_report.json` present |
| Quality gates | `.claude/evidence/quality_gates_run.json` shows PASS |
| TDD discipline | Tests exist for all domain logic |

---

## Completion

When done, state:
"Review complete. N findings created (X critical, Y high, Z medium, W low)"

The internal team will triage your findings and assign fixes to coding agents.
```

### Step 4: Display the Generated Prompt

After writing the file, display:

```
## Visiting Agent Prompt Generated

**File**: .claude/visiting_prompt_{role}_{date}.md
**Role**: {role}
**Project**: {project name}

### How to Use

1. **In a new Claude Code session**, paste the contents of the generated prompt
2. **Or** share the file with the visiting agent instance
3. The visiting agent will follow the entry protocol and review the project

### What the Visiting Agent Will Do

- Read your project manifest and understand current state
- Review {N} source directories for {role}-specific issues
- Check governance compliance (hexagonal, determinism, testing)
- Create findings with sequential BUG/IMPROVE IDs starting at {next_ids}
- Write report to `.claude/remediation/{role}_review_{date}.md`
- Update `remediation_tasks.md` and `manifest.yaml`

### Existing Remediation Context

- Current BUG count: {N}
- Current IMPROVE count: {N}
- New IDs will start at: BUG-{next} / IMPROVE-{next}
```

## Reference

Full visiting agent protocol: `~/.claude/agents/visit.md`
Agent governance: `~/.claude/docs/agent_governance.md`
Remediation format: `~/.claude/docs/remediation_format.md`

</visit>
